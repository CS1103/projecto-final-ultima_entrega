[![Review Assignment Due Date](https://classroom.github.com/assets/deadline-readme-button-22041afd0340ce965d47ae6ef1cefeee28c7c493a6346c4f15d667ab976d596c.svg)](https://classroom.github.com/a/Lj3YlzJp)
# Proyecto Final 2025-1: AI Neural Network
## **CS2013 ProgramaciÃ³n III** Â· Informe Final

### **DescripciÃ³n**

ImplementaciÃ³n en C++ de un agente para el juego Pong que utiliza una red neuronal multicapa entrenada desde cero. El proyecto incluye:

- Una librerÃ­a de Ã¡lgebra de tensores genÃ©ricos (Tensor<T,Â Rank>) con reshape, broadcasting y operaciones elementâ€‘wise.  
- Capas densas (Dense), funciÃ³n de activaciÃ³n ReLU y funciÃ³n de pÃ©rdida MSE, todo implementado sin dependencias de frameworks de deep learning.  
- Un entorno simulado (EnvGym) que replica la dinÃ¡mica bÃ¡sica de Pong y una clase PongAgent que, usando la red entrenada, decide acciones (mover la paleta hacia arriba, abajo o quedarse).  

### Contenidos

1. [Datos generales](#datos-generales)
2. [Requisitos e instalaciÃ³n](#requisitos-e-instalaciÃ³n)
3. [InvestigaciÃ³n teÃ³rica](#1-investigaciÃ³n-teÃ³rica)
4. [DiseÃ±o e implementaciÃ³n](#2-diseÃ±o-e-implementaciÃ³n)
5. [EjecuciÃ³n](#3-ejecuciÃ³n)
6. [AnÃ¡lisis del rendimiento](#4-anÃ¡lisis-del-rendimiento)
7. [Trabajo en equipo](#5-trabajo-en-equipo)
8. [Conclusiones](#6-conclusiones)
9. [BibliografÃ­a](#7-bibliografÃ­a)
10. [Licencia](#licencia)
---

### Datos generales

* **Tema**: Redes Neuronales en AI
* **Grupo**: `group_3_custom_name`
* **Integrantes**:
  * Requelmy Limaco Porras â€“ 202410015 (Responsable de investigaciÃ³n teÃ³rica, Pruebas y benchmarking)
  * Leonardo Martinez Aquino â€“ 202410148 (ImplementaciÃ³n del modelo, DocumentaciÃ³n y demo)
  * Jorge Armando MartÃ­nez Palomino - 202310094 (Desarrollo de la arquitectura y desarrollo del cÃ³digo)
---

### Requisitos e instalaciÃ³n

1. **Compilador**: GCC 11 o superior (con soporte para C++20)
2. **Dependencias**:
   * Ninguna (solo STL)
3. **InstalaciÃ³n**:

```bash
git clone https://github.com/CS1103/projecto-final-ultima_entrega
cd 
mkdir build && cd build
cmake ..
make
```
---

### 1. InvestigaciÃ³n teÃ³rica

**Objetivo**: Explorar los fundamentos de las redes neuronales artificiales y su aplicaciÃ³n en agentes inteligentes.

#### 1. Historia y evoluciÃ³n de las NNs

- **1943 â€“ 1960** : McCulloch y Pitts proponen la primera neurona binaria. Rosenblatt crea el PerceptrÃ³n (1958), pero sus limitaciones (no resuelve XOR) y se produce la falta de potencia computacional.
- **1980** : Renace el interÃ©s con el algoritmo de retropropagaciÃ³n (Rumelhart, 1986), que permite entrenar redes multicapa.
- **1990 â€“ 2000** : Aparecen redes mÃ¡s complejas como las CNN (LeCun) para visiÃ³n, y las LSTM (1997) para secuencias. Hinton introduce el preentrenamiento profundo, una tecnica dentro del deep learning (2006).
- **2010 â€“ hoy** : Auge del deep learning gracias al uso de GPUs. Surgen redes neuronales mejoradas como AlexNet (2012), GANs (2014), y Transformers (2017), que dieron origen a modelos como *GPT*, *BERT* y *ChatGPT*.

#### 2. Principales arquitecturas

- **MLP (PerceptrÃ³n Multicapa)**:  
  Redes feedforward totalmente conectadas. Utilizan funciones de activaciÃ³n como sigmoide o ReLU. Se emplean en tareas de clasificaciÃ³n y regresiÃ³n general.

- **CNN (Redes Convolucionales)**:  
  Usadas en visiÃ³n por computador. Aplican filtros para detectar patrones visuales y reducen la dimensionalidad. Ideales para imÃ¡genes y video.

- **RNN (Redes Recurrentes)**:  
  Procesan datos secuenciales (texto, audio, etc). Mantienen un estado interno para tener memoria. Algunas variantes populares son: LSTM, GRU.

#### 3. Algoritmos de entrenamiento

- **RetropropagaciÃ³n (Backpropagation)**:  
  Ajusta los pesos propagando el error desde la salida hacia las capas anteriores usando la regla de la cadena. Calcula el gradiente y actualiza pesos.

- **Funciones de pÃ©rdida**:
  - RegresiÃ³n: Error CuadrÃ¡tico Medio (MSE).
  - ClasificaciÃ³n: EntropÃ­a Cruzada (Cross-Entropy).

- **Optimizadores**:
  - SGD (Stochastic Gradient Descent): Actualiza pesos en minilotes, acelerando el entrenamiento.
  - Adam: Combina tasas de aprendizaje adaptativas con momentos. Muy eficiente y popular.
  - Otros: RMSprop, Adagrad, Adadelta, etc.

---

### 2. DiseÃ±o e implementaciÃ³n

#### 2.1 Arquitectura de la soluciÃ³n

* **Patrones de diseÃ±o**: ejemplo: Factory para capas, Strategy para optimizadores.
* **Estructura de carpetas (ejemplo)**:

  ```
  pong_ai/
  â”œâ”€â”€ include/
  â”‚   â””â”€â”€ utec/
  â”‚       â”œâ”€â”€ algebra/               
  â”‚       â”‚   â””â”€â”€ Tensor.h
  â”‚       â”œâ”€â”€ nn/                    
  â”‚       â”‚   â”œâ”€â”€ layer.h
  â”‚       â”‚   â”œâ”€â”€ dense.h
  â”‚       â”‚   â”œâ”€â”€ activation.h
  â”‚       â”‚   â”œâ”€â”€ loss.h
  â”‚       â”‚   â””â”€â”€ neural_network.h
  â”‚       â””â”€â”€ agent/                 
  â”‚           â”œâ”€â”€ PongAgent.h
  â”‚           â””â”€â”€ EnvGym.h
  â”œâ”€â”€ src/                           
  â”‚   â””â”€â”€ utec/
  â”‚       â””â”€â”€ agent/
  â”‚           â”œâ”€â”€ PongAgent.cpp
  â”‚           â””â”€â”€ EnvGym.cpp
  â”œâ”€â”€ tests/                         
  â”‚   â”œâ”€â”€ test_tensor.cpp
  â”‚   â”œâ”€â”€ test_neural_network.cpp
  â”‚   â””â”€â”€ test_agent_env.cpp
  â”œâ”€â”€ docs/                          
  â”œâ”€â”€ README.md
  â””â”€â”€ BIBLIOGRAFIA.md

  ```

## 2.2 Manual de uso y casos de prueba

### CÃ³mo ejecutar

El programa se compila y ejecuta desde CLion o por lÃ­nea de comandos. No requiere archivos de entrada.

```bash
./pong_ai
```
### Casos de prueba
**Test unitario de capa densa (Dense)**
* Se comprueba su funcionamiento correcto durante el entrenamiento del XOR.

* El forward realiza una multiplicaciÃ³n matricial y suma el bias.

* El backward propaga correctamente el gradiente hacia atrÃ¡s y calcula dW y db.

**Test de funciÃ³n de activaciÃ³n ReLU**
* Aplicada tras la primera capa Dense.

* Corrige los valores negativos a cero y permite el paso de valores positivos.

Se valida con propagaciÃ³n hacia adelante y hacia atrÃ¡s (forward y backward).

**Test de convergencia en dataset XOR**
* El modelo se entrena con 4 entradas representando el XOR lÃ³gico.

* Debido a errores en la ejecuciÃ³n o configuraciÃ³n, no se obtuvo convergencia completa en esta versiÃ³n.

---

### 3. EjecuciÃ³n

#### ğŸ”§ Pasos para ejecutar

1. Clona el repositorio y compila el proyecto:

```bash
git clone https://github.com/CS1103/projecto-final-ultima_entrega/
cd proyecto-pong-nn
mkdir build && cd build
cmake ..
make
```
---

### 4. AnÃ¡lisis del rendimiento

## 4. AnÃ¡lisis del rendimiento

### MÃ©tricas de entrenamiento

- **Iteraciones**:
- **Tiempo total de entrenamiento**:
- **PrecisiÃ³n final**: 

### Ventajas y desventajas

**Ventajas:**

- ImplementaciÃ³n ligera en C++.
- Dependencias mÃ­nimas (solo STL).
- Estructura clara y educativa del flujo forward â†’ backward â†’ optimize.

**Desventajas:**

- Sin paralelizaciÃ³n (entrenamiento en un solo hilo).
- Sin soporte de batches.
- Matriz multiplicada con bucles simples (poco eficiente).

### Mejoras futuras propuestas

- **Uso de BLAS**: Para acelerar las multiplicaciones, se podrÃ­a integrar bibliotecas como Eigen o OpenBLAS, aprovechando sus rutinas optimizadas en C++.
- **ParalelizaciÃ³n del entrenamiento**: Dividir el dataset en minibatches y aplicar hilos con std::thread permitirÃ­a escalar en CPUs multinÃºcleo, acelerando el entrenamiento.

---

### 5. Trabajo en equipo

| Tarea                     | Miembro  | Rol                       |
| ------------------------- | -------- | ------------------------- |
| InvestigaciÃ³n teÃ³rica     | Requelmy Limaco Porras (202410015) | Documentar bases teÃ³ricas |
| DiseÃ±o de la arquitectura | Leonardo Martinez Aquino (202410148) | UML y esquemas de clases  |
| ImplementaciÃ³n del modelo | Leonardo Martinez Aquino (202410148) | CÃ³digo C++ de la NN       |
| ImplementaciÃ³n del modelo | Jorge Armnando MartÃ­nez Palomino (202310094) | CÃ³digo C++ de la NN       |
| Pruebas y benchmarking    | Requelmy Limaco Porras (202410015 | GeneraciÃ³n de mÃ©tricas    |

---

### 6. Conclusiones

- **Logros**  
  â€¢ Se implementÃ³ desde cero un sistema de Ã¡lgebra de tensores genÃ©ricos (Tensor<T,Â Rank>) capaz de reshape, broadcasting y operaciones elementâ€‘wise.  
  â€¢ Se desarrollÃ³ una red neuronal modular en C++ (NeuralNetwork) con capas densas (Dense), activaciÃ³n ReLU, y funciÃ³n de pÃ©rdida MSE.  
  â€¢ Se integrÃ³ la red en un agente de Pong (PongAgent) y un entorno simulado (EnvGym), validando el pipeline completo de forward, backpropagation y actualizaciÃ³n de pesos.  

- **EvaluaciÃ³n**  
  â€¢ El cÃ³digo muestra una calidad adecuada: patrones de diseÃ±o claros, gestiÃ³n de memoria (copy/move) correcta, y un CMakeLists.txt fÃ¡cil de mantener.  
  â€¢ El rendimiento en CPU es aceptable para redes pequeÃ±as y batches reducidos, aunque presenta cuellos de botella en operaciones de multiplicaciÃ³n de matrices y broadcasting en tensores de mayor tamaÃ±o.

- **Aprendizajes** 
  â€¢ ProfundizaciÃ³n en el algoritmo de retropropagaciÃ³n: cachÃ© de activaciones, cÃ¡lculo de gradientes en Dense::backward y en MSELoss::backward.  
  â€¢ Manejo manual de memoria dinÃ¡mica en C++ (new/delete) y diseÃ±o de constructores copy/move para evitar fugas y dobles liberaciones.  
  â€¢ ComprensiÃ³n de la importancia de inicializaciÃ³n de pesos, escalado de gradientes y elecciÃ³n de tasa de aprendizaje.

- **Recomendaciones**  
  â€¢ Extender la librerÃ­a de tensores para soportar paralelismo (OpenMP/CUDA) y tipos de datos mixtos.  
  â€¢ Agregar funcionalidad de persistencia (guardar/cargar pesos) y herramientas de visualizaciÃ³n de mÃ©tricas (p.â€¯ej. grÃ¡ficas de pÃ©rdida y precisiÃ³n).  
  â€¢ Probar el agente en datasets reales (MNIST, CIFAR-10) o conectar con un entorno grÃ¡fico para evaluar rendimiento en escenarios mÃ¡s complejos.

---

### 7. BibliografÃ­a

[1] I. Goodfellow, Y. Bengio y A. Courville, *Deep Learning*, Cambridge, MA: MIT Press, 2016. [Online]. Disponible: https://www.deeplearningbook.org

[2] D. E. Rumelhart, G. E. Hinton y R. J. Williams, â€œLearning representations by back-propagating errors,â€ *Nature*, vol. 323, pp. 533â€“536, 1986. [Online]. Disponible: https://www.nature.com/articles/323533a0

[3] D. P. Kingma y J. Ba, â€œAdam: A method for stochastic optimization,â€ en *Proceedings of the 3rd International Conference on Learning Representations (ICLR)*, 2015. [Online]. Disponible: https://arxiv.org/abs/1412.6980

---

### Licencia

Este proyecto usa la licencia **MIT**. Ver [LICENSE](LICENSE) para detalles.

---
